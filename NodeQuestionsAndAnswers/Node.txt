Q1) What is node js?
Ans:-
-----
        Node.js is an open-source and cross-platform JavaScript runtime environment. It is a popular tool 
for almost any kind of project!Node.js runs the V8 JavaScript engine, the core of Google Chrome,
outside of the browser. This allows Node.js to be very performant.A Node.js app runs in a single process, 
without creating a new thread for every request. Node.js provides a set of asynchronous I/O primitives in 
mits standard library that prevent JavaScript code from blocking and generally, libraries in Node.js are
written using non-blocking paradigms, making blocking behavior the exception rather than the norm.
When Node.js performs an I/O operation, like reading from the network, accessing a database or the filesystem, 
instead of blocking the thread and wasting CPU cycles waiting, Node.js will resume the operations when the response
comes back.This allows Node.js to handle thousands of concurrent connections with a single server without introducing
the burden of managing thread concurrency, which could be a significant source of bugs.
Node.js has a unique advantage because millions of frontend developers that write JavaScript for the browser are 
now able to write the server-side code in addition to the client-side code without the need to learn a completely 
different language.In Node.js the new ECMAScript standards can be used without problems, as you don't have to wait
for all your users to update their browsers - you are in charge of deciding which ECMAScript version to use by
changing the Node.js version, and you can also enable specific experimental features by running Node.js with flags.


Q2) Differences between Node.js and the Browser?
Ans:-
------
        Both the browser and Node.js use JavaScript as their programming language. Building apps that run in the browser
is a completely different thing than building a Node.js application. Despite the fact that it's always JavaScript, 
there are some key differences that make the experience radically different.
From the perspective of a frontend developer who extensively uses JavaScript, Node.js apps bring with them a huge
advantage: the comfort of programming everything - the frontend and the backend - in a single language.
You have a huge opportunity because we know how hard it is to fully, deeply learn a programming language, and by using
the same language to perform all your work on the web - both on the client and on the server, you're in a unique
position of advantage.

**What changes is the ecosystem**
----------------------------------

In the browser, most of the time what you are doing is interacting with the DOM, or other Web Platform APIs like Cookies.
Those do not exist in Node.js, of course. You don't have the document, window and all the other objects that are provided by the browser.
And in the browser, we don't have all the nice APIs that Node.js provides through its modules, like the filesystem access functionality.
Another big difference is that in Node.js you control the environment. Unless you are building an open source application that anyone can 
deploy anywhere, you know which version of Node.js you will run the application on. Compared to the browser environment, where you don't get 
the luxury to choose what browser your visitors will use, this is very convenient.
This means that you can write all the modern ES2015+ JavaScript that your Node.js version supports. Since JavaScript
moves so fast, but browsers can be a bit slow to upgrade, sometimes on the web you are stuck with using older
JavaScript / ECMAScript releases. You can use Babel to transform your code to be ES5-compatible before shipping it to the browser, but in Node.js, you won't need that.
Another difference is that Node.js supports both the CommonJS and ES module systems (since Node.js v12), while in the browser we are starting
to see the ES Modules standard being implemented.
In practice, this means that you can use both require() and import in Node.js, while you are limited to import in 
the browser.

Q3) What is V8?
Ans:-
--------
V8 is the name of the JavaScript engine that powers Google Chrome. It's the thing that takes our JavaScript
and executes it while browsing with Chrome. V8 is the JavaScript engine i.e. it parses and executes JavaScript code.
The DOM, and the other Web Platform APIs (they all makeup runtime environment) are provided by the browser.
The cool thing is that the JavaScript engine is independent of the browser in which it's hosted. This key feature
enabled the rise of Node.js. V8 was chosen to be the engine that powered Node.js back in 2009, and as the popularity 
of Node.js exploded, V8 became the engine that now powers an incredible amount of server-side code written in JavaScript.
The Node.js ecosystem is huge and thanks to V8 which also powers desktop apps, with projects like Electron.

Other JS engines
----------------
Other browsers have their own JavaScript engine:
--Firefox has SpiderMonkey
--Safari has JavaScriptCore (also called Nitro)
--Edge was originally based on Chakra but has more recently been rebuilt using Chromium and the V8 engine.
and many others exist as well.
All those engines implement the ECMA ES-262 standard, also called ECMAScript, the standard used by JavaScript.
The quest for performance
V8 is written in C++, and it's continuously improved. It is portable and runs on Mac, Windows, Linux and several
other systems.
In this V8 introduction, we will ignore the implementation details of V8: they can be found on more authoritative
sites (e.g. the V8 official site), and they change over time, often radically.
V8 is always evolving, just like the other JavaScript engines around, to speed up the Web and the Node.js ecosystem.
On the web, there is a race for performance that's been going on for years, and we (as users and developers) benefit
a lot from this competition because we get faster and more optimized machines year after year.

Compilation
-----------
JavaScript is generally considered an interpreted language, but modern JavaScript engines no longer just interpret
JavaScript, they compile it.This has been happening since 2009, when the SpiderMonkey JavaScript compiler was added
to Firefox 3.5, and everyone followed this idea.
JavaScript is internally compiled by V8 with just-in-time (JIT) compilation to speed up the execution.
This might seem counter-intuitive, but since the introduction of Google Maps in 2004, JavaScript has evolved from a
language that was generally executing a few dozens of lines of code to complete applications with thousands to hundreds 
of thousands of lines running in the browser.
Our applications can now run for hours inside a browser, rather than being just a few form validation rules or simple scripts.
In this new world, compiling JavaScript makes perfect sense because while it might take a little bit more to have the
JavaScript ready, once done it's going to be much more performant than purely interpreted code.

Q4) What is npm?
Ans:-
-----
    npm is the standard package manager for Node.js.

    You can also install a specific package by running
    ---------------------------------------------------
    npm install <package-name>

--save-dev installs and adds the entry to the package.json file devDependencies
--no-save installs but does not add the entry to the package.json file dependencies
--save-optional installs and adds the entry to the package.json file optionalDependencies
--no-optional will prevent optional dependencies from being installed

Shorthands of the flags can also be used:

-S: --save
-D: --save-dev
-O: --save-optional

The difference between devDependencies and dependencies is that the former contains development tools, 
like a testing library, while the latter is bundled with the app in production.
As for the optionalDependencies the difference is that build failure of the dependency will not cause
installation to fail. But it is your program's responsibility to handle the lack of the dependency.
Read more about optional dependencies.

Versioning
-----------
In addition to plain downloads, npm also manages versioning, so you can specify any specific version of a
package, or require a version higher or lower than what you need.
Many times you'll find that a library is only compatible with a major release of another library.

You can install a specific version of a package, by running
-----------------------------------------------------------
npm install <package-name>@<version>

Q5) Difference b/w blocking and non blocking?
Ans:-
-----
This overview covers the difference between blocking and non-blocking calls in Node.js. This overview will
refer to the event loop and libuv but no prior knowledge of those topics is required. Readers are assumed to
have a basic understanding of the JavaScript language and Node.js callback pattern.

"I/O" refers primarily to interaction with the system's disk and network supported by libuv.

Blocking
--------
Blocking is when the execution of additional JavaScript in the Node.js process must wait until a non-JavaScript
operation completes. This happens because the event loop is unable to continue running JavaScript while a blocking 
operation is occurring.
In Node.js, JavaScript that exhibits poor performance due to being CPU intensive rather than waiting on a 
non-JavaScript operation, such as I/O, isn't typically referred to as blocking. Synchronous methods in the Node.js 
standard library that use libuv are the most commonly used blocking operations. Native modules may also have blocking 
methods.
All of the I/O methods in the Node.js standard library provide asynchronous versions, which are non-blocking, and 
accept callback functions. Some methods also have blocking counterparts, which have names that end with Sync.

Comparing Code
---------------------------------------------------------------------------------------
Blocking methods execute synchronously and non-blocking methods execute asynchronously.
Using the File System module as an example, this is a synchronous file read:

const fs = require('node:fs');
const data = fs.readFileSync('/file.md'); // blocks here until file is read
----------------------------------------------------------------------------
And here is an equivalent asynchronous example:

const fs = require('node:fs');
fs.readFile('/file.md', (err, data) => {
  if (err) throw err;
});

The first example appears simpler than the second but has the disadvantage of the second line blocking the 
execution of any additional JavaScript until the entire file is read. Note that in the synchronous version 
if an error is thrown it will need to be caught or the process will crash. In the asynchronous version, it
is up to the author to decide whether an error should throw as shown.

Let's expand our example a little bit:
--------------------------------------
const fs = require('node:fs');
const data = fs.readFileSync('/file.md'); // blocks here until file is read
console.log(data);
moreWork(); // will run after console.log
----------------------------------------------
And here is a similar, but not equivalent asynchronous example:

const fs = require('node:fs');
fs.readFile('/file.md', (err, data) => {
  if (err) throw err;
  console.log(data);
});
moreWork(); // will run before console.log
----------------------------------------------

In the first example above, console.log will be called before moreWork(). In the second example 
fs.readFile() is non-blocking so JavaScript execution can continue and moreWork() will be called first.
The ability to run moreWork() without waiting for the file read to complete is a key design choice that
allows for higher throughput.

Concurrency and Throughput
JavaScript execution in Node.js is single threaded, so concurrency refers to the event loop's capacity to
execute JavaScript callback functions after completing other work. Any code that is expected to run in a 
concurrent manner must allow the event loop to continue running as non-JavaScript operations, like I/O, are occurring.
As an example, let's consider a case where each request to a web server takes 50ms to complete and 45ms of that 50ms 
is database I/O that can be done asynchronously. Choosing non-blocking asynchronous operations frees up that 45ms 
per request to handle other requests. This is a significant difference in capacity just by choosing to use non-blocking
methods instead of blocking methods.
The event loop is different than models in many other languages where additional threads may be created to handle 
concurrent work.

Q6) What is JavaScript Asynchronous Programming and Callbacks?
Ans:-
------
Asynchronous means that things can happen independently of the main program flow.
In the current consumer computers, every program runs for a specific time slot and then it stops its 
execution to let another program continue their execution. This thing runs in a cycle so fast that it's 
impossible to notice. We think our computers run many programs simultaneously, but this is an illusion 
(except on multiprocessor machines).
Programs internally use interrupts, a signal that's emitted to the processor to gain the attention of the system.
Let's not go into the internals of this now, but just keep in mind that it's normal for programs to be asynchronous 
and halt their execution until they need attention, allowing the computer to execute other things in the meantime.
When a program is waiting for a response from the network, it cannot halt the processor until the request finishes.
Normally, programming languages are synchronous and some provide a way to manage asynchronicity in the language
or through libraries. C, Java, C#, PHP, Go, Ruby, Swift, and Python are all synchronous by default. Some of them 
handle async operations by using threads, spawning a new process.

**JavaScript
------------
JavaScript is synchronous by default and is single threaded. This means that code cannot create new threads and
run in parallel.

Lines of code are executed in series, one after another, for example:
---------------------------------------------------------------------
const a = 1;
const b = 2;
const c = a * b;
console.log(c);
doSomething();
-------------------------
But JavaScript was born inside the browser, its main job, in the beginning, was to respond to user actions, 
like onClick, onMouseOver, onChange, onSubmit and so on. How could it do this with a synchronous programming model?
The answer was in its environment. The browser provides a way to do it by providing a set of APIs that can handle 
this kind of functionality.
More recently, Node.js introduced a non-blocking I/O environment to extend this concept to file access, network 
calls and so on.

Callbacks
----------
You can't know when a user is going to click a button. So, you define an event handler for the click event. This event
handler accepts a function, which will be called when the event is triggered:
document.getElementById('button').addEventListener('click', () => {
  // item clicked
});

This is the so-called callback.

A callback is a simple function that's passed as a value to another function, and will only be executed when the 
event happens. We can do this because JavaScript has first-class functions, which can be assigned to variables and
passed around to other functions (called higher-order functions)
It's common to wrap all your client code in a load event listener on the window object, which runs the callback
function only when the page is ready:

window.addEventListener('load', () => {
  // window loaded
  // do what you want
});

Callbacks are used everywhere, not just in DOM events.
One common example is by using timers:

setTimeout(() => {
  // runs after 2 seconds
}, 2000);

**Handling errors in callbacks
------------------------------
How do you handle errors with callbacks? One very common strategy is to use what Node.js adopted: the
first parameter in any callback function is the error object: error-first callbacks
If there is no error, the object is null. If there is an error, it contains some description of the error
and other information.

const fs = require('node:fs');
fs.readFile('/file.json', (err, data) => {
  if (err) {
    // handle error
    console.log(err);
    return;
  }
  // no errors, process data
  console.log(data);
});

**The problem with callbacks
---------------------------
Callbacks are great for simple cases!
However every callback adds a level of nesting, and when you have lots of callbacks, the code starts to be
complicated very quickly:

window.addEventListener('load', () => {
  document.getElementById('button').addEventListener('click', () => {
    setTimeout(() => {
      items.forEach(item => {
        // your code here
      });
    }, 2000);
  });
});
JavaScript
This is just a simple 4-levels code, but I've seen much more levels of nesting and it's not fun.

How do we solve this?

Alternatives to callbacks
Starting with ES6, JavaScript introduced several features that help us with asynchronous code that do not 
involve using callbacks: Promises (ES6) and Async/Await (ES2017).

Q7) Event Emitter in Node js?
Ans:-
-----
  If you worked with JavaScript in the browser, you know how much of the interaction of the user is handled
through events: mouse clicks, keyboard button presses, reacting to mouse movements, and so on.
On the backend side, Node.js offers us the option to build a similar system using the events module.
This module, in particular, offers the EventEmitter class, which we'll use to handle our events.

You initialize that using
--------------------------------------------
const EventEmitter = require('node:events');
const eventEmitter = new EventEmitter();
--------------------------------------------

This object exposes, among many others, the on and emit methods.

emit is used to trigger an event
on is used to add a callback function that's going to be executed when the event is triggered
For example, let's create a start event, and as a matter of providing a sample, we react to that by just logging to the console:

eventEmitter.on('start', () => {
  console.log('started');
});

When we run
eventEmitter.emit('start');

the event handler function is triggered, and we get the console log.
You can pass arguments to the event handler by passing them as additional arguments to emit():

eventEmitter.on('start', number => {
  console.log(`started ${number}`);
});
eventEmitter.emit('start', 23);

Multiple arguments
---------------------------------------------
eventEmitter.on('start', (start, end) => {
  console.log(`started from ${start} to ${end}`);
});
eventEmitter.emit('start', 1, 100);
---------------------------------------------

The EventEmitter object also exposes several other methods to interact with events, like

once(): add a one-time listener
removeListener() / off(): remove an event listener from an event
removeAllListeners(): remove all listeners for an event
You can read more about these methods in the official documentation.

Q8) How to read environment variables from Node.js?
Ans:-
------
The process core module of Node.js provides the env property which hosts all the environment variables that were 
set at the moment the process was started.

The below code runs app.js and set USER_ID and USER_KEY.
------------------------------------------
USER_ID=239482 USER_KEY=foobar node app.js
--------------------------------------------

That will pass the user USER_ID as 239482 and the USER_KEY as foobar. This is suitable for testing,
however for production, you will probably be configuring some bash scripts to export variables.
------------------------------------------------------------------------
Note: process does not require a "require", it's automatically available.
------------------------------------------------------------------------

Here is an example that accesses the USER_ID and USER_KEY environment variables, which we set in above code.
-------------------------------------
process.env.USER_ID; // "239482"
process.env.USER_KEY; // "foobar"
-------------------------------------

In the same way you can access any custom environment variable you set.
Node.js 20 introduced experimental support for .env files.
Now, you can use the --env-file flag to specify an environment file when running your Node.js application.
Here's an example .env file and how to access its variables using process.env.
---------------
# .env file
PORT=3000
---------------

In your js file
---------------------------
process.env.PORT; // "3000"
----------------------------

Run app.js file with environment variables set in .env file.
----------------------------
node --env-file=.env app.js
----------------------------

This command loads all the environment variables from the .env file, making them available to the application on
process.env
Also, you can pass multiple --env-file arguments. Subsequent files override pre-existing variables defined 
in previous files.
-------------------------------------------------------
node --env-file=.env --env-file=.development.env app.js
-------------------------------------------------------

Note: if the same variable is defined in the environment and in the file, the value from the environment
takes precedence.

Q9) What is REPL in node.js ?
Ans:-
-----
The node command is the one we use to run our Node.js scripts:
--------------
node script.js
--------------

If we run the node command without any script to execute or without any arguments, we start a REPL session:
------
node
------

Note:REPL stands for Read Evaluate Print Loop, and it is a programming language environment (basically a console window) 
that takes single expression as user input and returns the result back to the console after execution. 
The REPL session provides a convenient way to quickly test simple JavaScript code.

If you try it now in your terminal, this is what happens:
----------
â¯ node
>
----------

The command stays in idle mode and waits for us to enter something.
Tip: if you are unsure how to open your terminal, google "How to open terminal on your-operating-system".

The REPL is waiting for us to enter some JavaScript code, to be more precise.
Start simple and enter
----------------------
> console.log('test')
test
undefined
>
----------------------

The first value, test, is the output we told the console to print, then we get undefined which is the
return value of running console.log(). Node read this line of code, evaluated it, printed the result,
and then went back to waiting for more lines of code. Node will loop through these three steps for every
piece of code we execute in the REPL until we exit the session. That is where the REPL got its name.

Node automatically prints the result of any line of JavaScript code without the need to instruct it to do so.
For example, type in the following line and press enter:
---------------
> 5 === '5'
false
>
---------------

Note the difference in the outputs of the above two lines. The Node REPL printed undefined after executed
console.log(), while on the other hand, it just printed the result of 5 === '5'. You need to keep in mind
that the former is just a statement in JavaScript, and the latter is an expression.

In some cases, the code you want to test might need multiple lines. For example, say you want to define a 
function that generates a random number, in the REPL session type in the following line and press enter:
----------------------------
function generateRandom() {
...
----------------------------

The Node REPL is smart enough to determine that you are not done writing your code yet, and it will go into
a multi-line mode for you to type in more code. Now finish your function definition and press enter:
----------------------------
function generateRandom() {
...return Math.random()
}
undefined
----------------------------

The _ special variable
If after some code you type _, that is going to print the result of the last operation.

The Up arrow key
If you press the up arrow key, you will get access to the history of the previous lines of code executed 
in the current, and even previous REPL sessions.

Dot commands
The REPL has some special commands, all starting with a dot .. They are

.help: shows the dot commands help
.editor: enables editor mode, to write multiline JavaScript code with ease. Once you are in this mode, enter ctrl-D to run the code you wrote.
.break: when inputting a multi-line expression, entering the .break command will abort further input. Same as pressing ctrl-C.
.clear: resets the REPL context to an empty object and clears any multi-line expression currently being input.
.load: loads a JavaScript file, relative to the current working directory
.save: saves all you entered in the REPL session to a file (specify the filename)
.exit: exits the repl (same as pressing ctrl-C two times)
The REPL knows when you are typing a multi-line statement without the need to invoke .editor.

For example if you start typing an iteration like this:
-----------------------------
[1, 2, 3].forEach(num => {
-----------------------------  

and you press enter, the REPL will go to a new line that starts with 3 dots, indicating you can now continue to
work on that block.

-----------------------
... console.log(num)
... })
-----------------------
Bash
If you type .break at the end of a line, the multiline mode will stop and the statement will not be executed.

Run REPL from JavaScript file
We can import the REPL in a JavaScript file using repl.
----------------------------------
const repl = require('node:repl');
----------------------------------

Using the repl variable we can perform various operations. To start the REPL command prompt, type in the following line
-------------
repl.start();
-------------

Run the file in the command line.

---------------
node repl.js
---------------

You can pass a string which shows when the REPL starts. The default is '> ' (with a trailing space), but we 
can define custom prompt.

--------------------------------
// a Unix style prompt
const local = repl.start('$ ');
--------------------------------

You can display a message while exiting the REPL
--------------------------------
local.on('exit', () => {
  console.log('exiting repl');
  process.exit();
});
--------------------------------


Q10) What is Routing?
Ans:-
-------
    Routing defines the way in which the client requests are handled by the application endpoints.

**Types of url
-----------------
  1) File based url
  eg:- www.eirj.com/index.html
  in this example www.eirj.com is domain name and index.html is file 

  2) Resoure based url
  eg:- www.eirj.com/about 
  int this example www.eirj.com is domain name and about is Resoure 

  Routing basically means implementing diffrent actions for diffrent URLs.
  These actions can be implemented in diffrent ways, for example, by creating a function. 

**Route parameter
---------------- 
 eg:- www.eirj.com/about/id 
 in this example www.eirj.com is domain name, about is Resoure and id is parameter. 

**Query String 
----------------
 eg:- www.eirj.com/books?author=john&id=2 
 in this example after question mark whatever I have written is query string. 
 there is two query string author and id and both query strings are available in key value pair.


 Q11) Diffrence between search param and query params?
 Ans:- Both refer to the same thing â€” key-value pairs in the URL after ?
  The term â€œsearch paramsâ€ is used more often in frontend/browser code (with URLSearchParams).
  â€œquery paramsâ€ is the broader and more common term, especially in backend or API contexts.

  1. Query Parameters (Backend/API Perspective)
  
  -> Part of the URL after the ?

  -> Sent to the server in the HTTP request

  -> Used for filtering, pagination, searching, etc.
-------------------------------------------------
example-
  GET /users?page=2&limit=10
in node js with express js
  req.query.page // '2'
  req.query.limit // '10'
  -------------------------------------------------

2. Search Parameters (Frontend/Browser Perspective)

-> Term used in browser-side JavaScript (DOM APIs)

-> Accessed using the URLSearchParams API

------------------------------------------------
const params = new URLSearchParams(window.location.search);
const page = params.get('page'); // '2'
------------------------------------------------

URL Breakdown:
https://example.com/products?category=books&sort=price

 -> ?category=books&sort=price â†’ query string

 -> category and sort â†’ query/search parameters

 -> Use .query in backend (e.g., Express)

 -> Use URLSearchParams in frontend


 Q12) how to use commmand line in node js?

 Ans:- Node.js allows interaction with the command line through several methods. Here's a breakdown:
1. Running Node.js Scripts:
  -> Using the node command: The most common way is to use the node command followed by the script's file name.

  eg:-
  ----------------------
    node your_script.js

  -> Shebang: Adding a shebang line at the beginning of your script allows direct execution (on Unix-like systems).

  eg:-
  ---------------------
      #!/usr/bin/env node
    // Your code here

2. Interacting with the Command Line:
console.log(): The console.log() function is used to print output to the command line. 
It can handle strings, numbers, objects, and more.

eg:-
---------------------------
    console.log("Hello, command line!");
    const x = 10;
    console.log("The value of x is:", x); 

Command-line arguments: Access command-line arguments passed to the script using process.argv.
    console.log(process.argv);

    The first two elements of the array are the node executable path and the script path, respectively.
    The remaining elements are the arguments.
    -> Using child_process module: Execute shell commands from within Node.js using the child_process module.

    example:-
    --------------------------------------
        const { exec } = require('child_process');
    exec('ls -l', (error, stdout, stderr) => {
      if (error) {
        console.error(`Error: ${error}`);
        return;
      }
      console.log(`stdout: ${stdout}`);
      console.error(`stderr: ${stderr}`);
    });
    --------------------------------------

    3. Node.js REPL (Read-Eval-Print Loop):
The Node.js REPL is an interactive environment for executing JavaScript code.
To start the REPL, type node in your terminal without any file argument.
You can enter JavaScript code directly and it will be executed immediately.
Dot commands: REPL has special dot commands for various actions:
.help: Shows help for dot commands.
.editor: Enters editor mode for multi-line input.
.clear: Clears the REPL context.
.load: Loads a JavaScript file.
.save: Saves the REPL session to a file.
.exit: Exits the REPL.

    4. Packages for Command Line Interfaces:
commander: A popular library to handle command-line arguments.
yargs: Another library for parsing command-line arguments.
These methods enable you to create powerful command-line tools and interact with the system using Node.js.

Q13) Transaction management in node js?
Ans:- Transaction management in Node.js, particularly when interacting with databases, ensures data integrity 
and consistency by treating a series of operations as a single, atomic unit. This means either all operations 
within a transaction succeed and are committed, or if any operation fails, the entire transaction is rolled back,
and no changes are made to the database.

Key principles and steps for managing transactions in Node.js:
Database Driver/ORM Integration:
Most database drivers (e.g., mysql, pg for PostgreSQL, mongodb for MongoDB) and Object-Relational Mappers (ORMs)
like Sequelize or Mongoose provide built-in support for transactions.
These tools expose methods to initiate, commit, and roll back transactions.

Starting a Transaction: 
A transaction is typically initiated by calling a specific method on the database connection or session object 
(e.g., beginTransaction() in SQL-based databases, startSession() and startTransaction() in MongoDB).

Executing Transactional Queries/Operations:
All database operations intended to be part of the atomic unit are executed within the context of the active transaction.
This often involves passing a transaction object or session to the individual query or operation calls.

Committing the Transaction:
If all operations within the transaction execute successfully, the changes are made permanent in the database by committing 
the transaction (e.g., commit() or commitTransaction()).

Rolling Back the Transaction:
If any error occurs during the execution of operations within the transaction, or if a specific condition is not met, the
transaction is aborted, and all changes made during that transaction are undone (e.g., rollback() or abortTransaction()). 
This ensures that the database remains in a consistent state.

Error Handling and Session Management:
Robust error handling is crucial to catch exceptions and trigger rollbacks when necessary.
For session-based transactions (common in NoSQL databases like MongoDB), ending the session after the transaction is 
committed or aborted is important for resource management.

Example (Conceptual with a SQL-like database):
------------------------------------------------------------------------------------
const connection = await pool.getConnection(); // Get a database connection
try {
    await connection.beginTransaction(); // Start the transaction

    // Execute multiple database operations within the transaction
    await connection.query('UPDATE accounts SET balance = balance - ? WHERE id = ?', [amount, senderId]);
    await connection.query('UPDATE accounts SET balance = balance + ? WHERE id = ?', [amount, receiverId]);

    await connection.commit(); // Commit the transaction if all operations succeed
    console.log('Transaction committed successfully.');
} catch (error) {
    await connection.rollback(); // Rollback the transaction if an error occurs
    console.error('Transaction rolled back:', error);
} finally {
    connection.release(); // Release the connection back to the pool
}
----------------------------------------------------------------------------------------

Q14) What is webhooks?
Ans:- Webhooks are a method for applications to communicate in real-time by sending automated messages or 
information to other applications when specific events occur. They are essentially user-defined HTTP callbacks 
that get triggered when certain events happen in a system. 

ðŸŸ¢Key Concepts:
Event-driven:
Webhooks are triggered by specific events within an application, such as a new user registration, a payment being processed, 
or a code change being committed. 

Real-time:
Webhooks provide near real-time updates, as the receiving application is notified immediately when the event occurs. 

HTTP callbacks:
Webhooks utilize HTTP requests (typically POST) to send data to a designated URL (the webhook endpoint). 

One-way communication:
Webhooks are unidirectional, meaning data is sent from the source application to the receiving application, unlike WebSockets
which are bidirectional. 

ðŸŸ¢How Webhooks Work:
-------------------------------------------
1. Registration:
The receiving application registers a webhook endpoint (a URL) with the source application, indicating which events it's interested in. 
2. Event Trigger:
When a registered event occurs in the source application, it sends an HTTP POST request to the registered webhook URL. 
3. Payload Delivery:
The POST request contains a payload of data related to the event. 
4. Processing:
The receiving application processes the data in the payload and takes appropriate action, such as updating a database, sending 
a notification, or triggering a workflow. 

ðŸŸ¢Use Cases:
------------------------------------------
Notifications: Sending notifications to users or other applications about events like new orders, code commits, or 
social media mentions. 

Data synchronization: Automatically syncing data between different applications, such as customer data between a CRM and 
an email marketing platform. 

Workflow automation: Triggering automated workflows based on specific events, such as deploying code to a production server 
when a new commit is pushed. 

Continuous Integration/Continuous Deployment (CI/CD): Triggering CI pipelines when code is pushed to a repository. 
Payment processing: Notifying accounting software when a payment is received. 

ðŸŸ¢Benefits of Webhooks:
------------------------------------------
Real-time updates: Receive data as it happens, eliminating the need for polling. 
Reduced overhead: Webhooks are more efficient than polling, as they only send data when events occur. 
Simplified integration: Webhooks provide a simple and standardized way for applications to communicate. 
Event-driven automation: Enable the creation of powerful, automated workflows. 

Security Considerations:
Authentication: Verifying the authenticity of the webhook request is crucial to prevent malicious actors from sending fake events.
Signature validation: Using HMAC algorithms with a shared secret key to verify the request's signature is a common security practice.
Timestamp validation: Validating the timestamp of the request can help prevent replay attacks. 

Q15) What is buffer in memory? 
Ans:- In Node.js, a Buffer is a global object used to handle and manipulate raw binary data directly in memory. It represents a 
fixed-size chunk of memory allocated outside the V8 JavaScript engine's heap.

ðŸŸ¢Key characteristics and uses of Buffers in Node.js:
----------------------------------------------------
Binary Data Handling:
Buffers are specifically designed for working with binary data, such as images, audio/video files, network packets, or raw data 
from I/O operations.

Fixed Size:
Once a Buffer is created, its size cannot be changed. This fixed-size nature allows for efficient memory management when dealing
with large amounts of data.

Direct Memory Access:
Buffers provide a low-level way to interact with raw bytes, allowing for direct manipulation of memory. This is crucial for 
performance-critical operations.

Efficiency:
Buffers are more efficient than JavaScript strings for handling binary data because they avoid the overhead of encoding and 
decoding data into string formats.

I/O Operations:
They are fundamental for handling I/O operations like reading from or writing to files, or sending/receiving data over network connections.

Streams:
Buffers are commonly used in conjunction with Node.js streams, where data is processed in chunks, and Buffers serve as the temporary
storage for these chunks.

ðŸŸ¢Creating Buffers:
----------------------------------
-> Buffer.alloc(size): Creates a new Buffer of a specified size and initializes it with zeros.
-> Buffer.allocUnsafe(size): Creates a new Buffer of a specified size without initializing it. This can be faster but might 
   expose sensitive data from previously allocated memory.
-> Buffer.from(data): Creates a new Buffer from various data sources like strings, arrays, or other Buffers.

ðŸŸ¢Common Buffer Methods:-

->  buf.toString(): Converts the Buffer's content to a string using a specified encoding (e.g., 'utf8', 'hex', 'base64').
->  buf.write(): Writes data to the Buffer.
->  buf.copy(): Copies data from one Buffer to another.
->  buf.length: Returns the size of the Buffer in bytes.
->  In essence, Buffers are a crucial part of Node.js for efficiently managing and interacting with binary data, particularly in scenarios involving I/O and network communication.

Q16) What is Streams in node js ? 
Ans:- Streams in Node.js are a fundamental concept for handling data flow, especially when dealing with large datasets or 
I/O operations like file manipulation and network communication. They represent a collection of data that may not be available 
all at once and doesn't necessarily need to fit entirely in memory.

ðŸŸ¢Key characteristics of Node.js Streams:
-------------------------------------
Efficiency:
Streams process data in chunks, reducing memory consumption and enabling faster processing of large files or network requests 
compared to loading entire datasets into memory.

Asynchronous Nature:
Streams are built upon the EventEmitter class, allowing them to emit various events (like data, end, error, finish) at different 
stages of data processing. This enables asynchronous handling of data as it becomes available.

Piping:
A powerful feature that allows connecting the output of one stream to the input of another, creating a pipeline for data 
transformation and transfer.

ðŸŸ¢Types of Streams in Node.js:
-----------------------------------
Readable Streams:
From which data can be read (e.g., fs.createReadStream() for reading from a file).
Writable Streams:
To which data can be written (e.g., fs.createWriteStream() for writing to a file).
Duplex Streams:
Streams that are both Readable and Writable (e.g., net.Socket for network communication).
Transform Streams:
A type of Duplex stream that can modify or transform the data as it is written and read (e.g., zlib.createDeflate() 
for data compression). 

Example of using Streams (Piping):
-------------------------------------------------------------
const fs = require('fs');

const readableStream = fs.createReadStream('input.txt');
const writableStream = fs.createWriteStream('output.txt');

readableStream.pipe(writableStream); // Pipes data from input.txt to output.txt

readableStream.on('end', () => {
  console.log('File reading complete.');
});

writableStream.on('finish', () => {
  console.log('File writing complete.');
});

readableStream.on('error', (err) => {
  console.error('Error reading file:', err);
});

writableStream.on('error', (err) => {
  console.error('Error writing file:', err);
});
-------------------------------------------------------------

Q17) What is clusture module in node js? 
Ans:- 
Node.js runs on a single thread by default.
The Cluster module lets you create child processes (workers) that share the same server port.
It helps take advantage of multi-core CPUs to improve performance and scalability.

ðŸ”· Why use Cluster?
Node.js is single-threaded, so it can only use one CPU core per process.
Cluster creates multiple worker processes to handle concurrent requests.
If one worker crashes, others can keep running.

ðŸ”· How it works?
The master process spawns multiple worker processes.
Workers share the same server port.
Master distributes incoming connections among workers (round-robin).

ðŸ”· Basic Example of Cluster
-------------------------------------------------------
const cluster = require('cluster');
const http = require('http');
const os = require('os');

if (cluster.isMaster) {
  const numCPUs = os.cpus().length;
  console.log(`Master process is running. Spawning ${numCPUs} workers.`);

  // Fork workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died. Spawning a new one.`);
    cluster.fork();  // Restart worker
  });

} else {
  // Worker processes run the server
  http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Hello from worker ${process.pid}\n`);
  }).listen(8000);

  console.log(`Worker ${process.pid} started`);
}
----------------------------------------------------

ðŸ”· Key Points:
------------------------
| Feature            | Description                           |
| ------------------ | ------------------------------------- |
| `cluster.isMaster` | True if the current process is master |
| `cluster.fork()`   | Creates a new worker process          |
| Workers share port | All workers listen on the same port   |
| Fault tolerance    | Master can restart workers on failure |
| Load balancing     | Distributes requests across workers   |


ðŸ”· When to Use
For CPU-intensive apps or to handle high traffic.
When you want to utilize all CPU cores in your server.

Q18) What is Distributed Messeging Queues?
Ans:- Distributed Messaging Queues: Kafka and RabbitMQ

### Key Concepts and Definitions

- **Messaging Queue (MQ):** A system where a **producer** publishes messages to a **queue**, and a **consumer** reads and processes these messages asynchronously.
- **Advantages of MQ:**
  - **Asynchronous processing:** Decouples producer and consumer, reducing latency.
  - **Retry capability:** Handles failures by retrying message processing.
  - **Pace matching:** Balances load when producers send messages faster than consumers can process.
  - **Reliability:** Ensures message durability and fault tolerance.

---

### Messaging Patterns

| Pattern          | Description                                                                              | Key Point                                         |
|------------------|------------------------------------------------------------------------------------------|--------------------------------------------------|
| **Point-to-Point**| Message is consumed by **only one consumer** from the queue.                            | Single message â†’ Single consumer                  |
| **Pub/Sub**       | Message is **broadcast** to multiple queues; multiple consumers can process the message.| Single message can be consumed by multiple consumers |

---

### Kafka: Architecture and Components

- **Producer:** Sends messages to Kafka brokers.
- **Broker:** Kafka server that hosts topics.
- **Topic:** Named stream of messages; logical grouping.
- **Partition:** Subdivision of a topic; actual storage unit.
- **Offset:** Position marker within a partition indicating which messages have been consumed.
- **Consumer:** Reads messages from partitions.
- **Consumer Group:** Multiple consumers read partitions in parallel; each partition read by only one consumer in the group.
- **Cluster:** Group of brokers working together.
- **Zookeeper:** Manages broker coordination, metadata, leader election.

**Kafka Message Structure:**

| Field     | Description                                              | Mandatory          |
|-----------|----------------------------------------------------------|--------------------|
| Key       | Identifier for partition assignment (e.g., car ID)       | Optional           |
| Value     | Actual message content                                   | Mandatory          |
| Topic     | Topic name                                               | Mandatory          |
| Partition | Specific partition number                                | Optional           |

**Partition Assignment Logic:**

- If key is present â†’ message assigned to partition via hash of key.
- If key empty but partition specified â†’ message goes to that partition.
- If neither key nor partition specified â†’ round-robin distribution.

---

### Kafka Message Flow and Fault Tolerance

- **Offset Tracking:** Zookeeper tracks committed offset per consumer group, ensuring consumers know where to resume after failure.
- **Consumer Failure:** Other consumers in the group take over partition reading from last committed offset.
- **Leader-Follower Model:** Partitions have a **leader** broker and one or more **replica followers** for fault tolerance. Writes and reads go through the leader; followers replicate data.
- **Cluster Scaling:** Multiple brokers distribute partitions; data and load spread across machines.
- **Handling Queue Size Limit:** Adding more brokers and partitions distributes load and storage.
- **Retry Mechanism:** Failed message processing retries up to a configured limit; unprocessable messages are sent to a **dead letter queue**.

---

### RabbitMQ: Architecture and Differences from Kafka

- **Producer â†’ Exchange â†’ Queue â†’ Consumer** flow.
- **Exchange:** Routes messages to queues based on routing keys and exchange type.
- **Exchange Types:**
  - **Fanout:** Broadcasts messages to all bound queues.
  - **Direct:** Routes messages to queues with exact routing key match.
  - **Topic:** Supports wildcard routing keys for flexible routing.
- **Push-Based Model:** RabbitMQ **pushes** messages to consumers as soon as they arrive.
- **Retry Handling:** If a consumer fails to process a message, it can **requeue** the message for retry. After max retries, message moves to a dead letter queue.
- **No Offset Concept:** Unlike Kafka, RabbitMQ does not track consumer offsets; it relies on message acknowledgments and requeueing.

---

### Use Cases Highlighted

- **E-commerce Notifications:** Asynchronous notification sending to reduce latency and improve user experience.
- **Pace Matching:** Handling varying message production rates with slower consumer processing.
- **Real-time Location Tracking:** In a cab service, thousands of GPS location updates are sent every few seconds. MQs help buffer and pace the data consumption for dashboard updates.

---

### Important Interview Insights

- Understand **difference between point-to-point and pub/sub** messaging.
- Explain Kafkaâ€™s **partition, offset, consumer group, leader-follower replication, and Zookeeper role**.
- Know RabbitMQâ€™s **exchange types and routing mechanisms**.
- Be able to discuss **failure scenarios**:
  - What happens if queue size limit is reached?
  - What if a consumer goes down?
  - How retries and dead letter queues work.
- Understand **Kafka is pull-based** (consumer polls broker) while **RabbitMQ is push-based** (broker pushes message to consumer).

---

### Summary Table: Kafka vs RabbitMQ

| Feature                | Kafka                                      | RabbitMQ                                  |
|------------------------|--------------------------------------------|------------------------------------------ |
| Model                  | Pull-based (consumer polls for messages)   | Push-based (broker pushes messages)       |
| Message Routing        | Topics â†’ Partitions                        | Exchanges â†’ Queues                        |
| Message Ordering       | Partition level ordering                   | Queue level ordering                      |
| Consumer Tracking      | Offset stored in Zookeeper                 | Ack-based, no offsets                     |
| Retry Handling         | Offset management + Dead Letter Queue      | Requeue + Dead Letter Queue               |
| Scalability            | High, via partitions and broker clusters   | Moderate, via queues and exchanges        |
| Use Case Focus         | High throughput, distributed systems       | Flexible routing, complex routing patterns|

---

Q19) suppose there is 10000 user accessing server in node js how can we handle concurrency?
Ans:-  To handle 10,000 concurrent users in a Node.js server, you need to design for high concurrency, non-blocking operations, scalability, and fault-tolerance.
Below is a clear, practical guide you can follow ðŸ‘‡

----------------------------------------------------------------------------------------------------------

âœ… How Node.js Handles Concurrency

Node.js is single-threaded, but it handles multiple requests using:

Event Loop

Non-blocking I/O

Async operations (Promises, async/await)

As long as you avoid blocking the thread, Node.js can handle thousands of connections.

ðŸ”¥ Techniques to Handle 10,000+ Concurrent Users
1. Avoid Blocking Code

Never block the event loop.

â›” Wrong (blocking):
---------------------------------------------------------
const fs = require("fs");
const data = fs.readFileSync("file.txt"); // Blocks thread
---------------------------------------------------------

âœ… Correct (non-blocking):
---------------------------------------------------------
fs.readFile("file.txt", (err, data) => {});
--------------------------------------------------------

Also avoid:

--CPU heavy calculations
--Large loops
--JSON.stringify of big objects
--Sync DB calls


2. Use Cluster Mode (Multi-core CPU Utilization)

Node runs on 1 CPU core only, but with clustering you can use all cores.

Example using PM2:

ðŸ‘‰ PM2 Auto-clustering:
--------------------------------
pm2 start server.js -i max
--------------------------------

This spawns workers equal to number of CPU cores (ex: 8 workers).
ðŸ‘‰ Native cluster module:
--------------------------------
const cluster = require('cluster');
const os = require('os');

if (cluster.isMaster) {
  const cpus = os.cpus().length;
  for (let i = 0; i < cpus; i++) cluster.fork();
} else {
  require("./app");
}
---------------------------------

3. Use Load Balancer (Nginx / AWS ELB)
A load balancer sits in front and distributes traffic:
---------------------------------------------------
Client â†’ Load Balancer â†’ Node.js Cluster â†’ Database
---------------------------------------------------
Nginx example:
---------------------------------------------------
upstream app_cluster {
    server 127.0.0.1:3001;
    server 127.0.0.1:3002;
    server 127.0.0.1:3003;
}
server {
    location / {
        proxy_pass http://app_cluster;
    }
}
---------------------------------------------------


4. Use Message Queues for Heavy Tasks

If your app sends:
-Emails
-PDFs
-Videos
-Push notifications
-Reports

Move it to a queue:

Common queues:
-BullMQ (Redis)
-RabbitMQ
-Kafka

Example job queue (BullMQ):
---------------------------------------------------
queue.add("sendEmail", { email: "test@mail.com" });
---------------------------------------------------
Workers run in background and keep your server free.

5. Use Connection Pooling for Database

Do NOT open/close DB connections per request.
MySQL example:
--------------------------------------------
const pool = mysql.createPool({
  connectionLimit: 20,
});
--------------------------------------------

MongoDB:
Use single shared client:
--------------------------------------------
const client = new MongoClient(uri);
await client.connect();
--------------------------------------------

6. Use Caching (Redis)
Offload repeated queries using cache:
------------------------------------------------
const user = await redis.get("user:123");

if (!user) {
    const result = await db.users.findOne({ id: 123 });
    redis.set("user:123", JSON.stringify(result));
}
--------------------------------------------------
Cache helps reduce DB load drastically.


7. Horizontal Scaling

If traffic grows even more:
--------------------------
Server 1
Server 2
Server 3
Server 4
-------------------------

Use:
-Kubernetes
-Docker Swarm
-AWS Auto Scaling

8. Use Rate Limiting to Protect Server

Prevent one user from overloading your server:
-----------------------------------------------
import rateLimit from 'express-rate-limit';

app.use(rateLimit({
    windowMs: 60_000,
    max: 100
}));
-----------------------------------------------


9. Performance Monitoring

Use:
-PM2 Monitoring
-Grafana + Prometheus
-New Relic
-Datadog


ðŸ”¥ High-Performance Server Template
------------------------------------------------
import express from "express";
import cluster from "cluster";
import os from "os";

if (cluster.isPrimary) {
    const cpuCount = os.cpus().length;
    for (let i = 0; i < cpuCount; i++) cluster.fork();
} else {
    const app = express();
    app.get("/", (req, res) => {
        res.send("Hello 10k users!");
    });
    app.listen(3000);
}
-------------------------------------------------


âœ… Summary (Easy to Understand)

| Technique             | Why Needed?                        |
| --------------------- | ---------------------------------- |
| Non-blocking I/O      | Node can handle thousands of users |
| Clustering            | Use all CPU cores                  |
| Load Balancer         | Split traffic across servers       |
| Message Queues        | Offload heavy tasks                |
| DB connection pooling | Prevent DB overload                |
| Redis caching         | Reduce DB queries                  |
| Horizontal scaling    | Add more servers                   |
| Rate limiting         | Prevent abuse                      |


Q20) Why background jobs needed in node js environment?
Ans:- A background job in Node.js is a task that runs asynchronously and outside the main request/response cycle, so your Node.js server doesn't get blocked.

These jobs are handled by workers, not by the main API thread.

âœ… Simple Explanation

When a user hits your API, you respond immediately and push heavy work to a background worker.

ðŸ‘‰ Main server = handles requests
ðŸ‘‰ Background worker = handles slow tasks

ðŸŽ¯ Why Background Jobs Are Used?
To avoid blocking your Node.js server.

Common use cases:
--------------------
-Sending emails
-Generating PDFs
-Processing images & videos
-Generating reports
-Payment processing
-Sending notifications
-Data cleanup
-Cron jobs (daily tasks)
-These tasks may take 1â€“30 seconds or more, so we send them to the background.

ðŸ”¥ Example Without Background Job (BAD)
----------------------------------------
app.post("/register", async (req, res) => {
  await sendEmail();   // â›” Blocks server
  res.send("User registered");
});
----------------------------------------
If 100 users register, your API becomes slow or crashes.

âš¡ With Background Job (GOOD)
----------------------------------------
app.post("/register", async (req, res) => {
  emailQueue.add({ email: req.body.email });
  res.send("User registered");
});
----------------------------------------

Worker:
----------------------------------------
const worker = new Worker("emailQueue", async job => {
  await sendEmail(job.data.email);
});
----------------------------------------

The server is free instantly.
The worker sends the email in background.

ðŸ’¡ How Background Jobs Work Internally

a) API adds a job to a queue â†’ (Redis / RabbitMQ / Kafka)
b) A separate worker process listens to the queue
c) Worker picks a job
d) Worker executes the heavy task
e) Marks the job completed

ðŸ§° Popular Background Job Libraries in Node.js

1. BullMQ (Redis - most popular)
-Fast
-Easy
-Supports scheduling

Works well with queues & workers

2. Agenda
-Cron + jobs
-Uses MongoDB

3. Bree
Pure Node.js worker threads

4. RabbitMQ
Enterprise-grade message queue

